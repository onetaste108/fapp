{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all size 306176\n",
      "supposed 306176\n",
      "weights shape (307200, 768)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "features_dir = '../weights'\n",
    "fps = os.listdir(features_dir)\n",
    "\n",
    "indices = [int(f.split('.')[0]) for f in fps]\n",
    "indices.sort()\n",
    "\n",
    "all_size = 0\n",
    "features = []\n",
    "for idx in indices:\n",
    "\t# if idx == 0: continue\n",
    "\tarr = np.load(features_dir+'/'+f'{idx}.npy')[0]\n",
    "\tarr = np.float32(arr)\n",
    "\t# print(f'{idx+512}.npy', arr[0][:5])\n",
    "\t# print([arr[i][0] for i in range(8)])\n",
    "\tall_size += arr.shape[0]\n",
    "\tfeatures.append(arr)\n",
    "\tif idx == 0:\n",
    "\t\tfeatures.append(np.ones_like(arr)*10.0)\n",
    "\n",
    "features_list = features\n",
    "\n",
    "print('all size', all_size)\n",
    "print('supposed', indices[-1]+1024)\n",
    "\n",
    "for f in features:\n",
    "\tassert f.shape[1] == 768, f.shape\n",
    "features = np.concatenate(features, 0)\n",
    "\n",
    "print('weights shape', features.shape)\n",
    "\n",
    "\n",
    "fap_features = features\n",
    "fap_features_ = torch.from_numpy(fap_features).to(device)\n",
    "fap_features = fap_features_\n",
    "fap_features /= fap_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "def find_best_feature(image_features, fap_features, size=10):\n",
    "\timage_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\tsimilarity = (100.0 * image_features @ fap_features.T).softmax(dim=-1)\n",
    "\tvalues, best = similarity[0].topk(size)\n",
    "\tvalues = values.cpu().numpy()\n",
    "\tbest = best.cpu().numpy()\n",
    "\treturn values, best\n",
    "\n",
    "def sim_image(image, fap_features, size=10):\n",
    "\timage = preprocess(image).unsqueeze(0).to(device)\n",
    "\twith torch.no_grad():\n",
    "\t\timage_features = model.encode_image(image)\n",
    "\treturn find_best_feature(image_features, fap_features, size)\n",
    "\n",
    "def sim_text(text, fap_features, size=10):\n",
    "\ttext = clip.tokenize([text]).to(device)\n",
    "\twith torch.no_grad():\n",
    "\t\timage_features = model.encode_text(text)\n",
    "\treturn find_best_feature(image_features, fap_features, size)\n",
    "\n",
    "def sim_db(id, fap_features, size=10):\n",
    "\tfeat = fap_features[id:id+1]\n",
    "\treturn find_best_feature(feat, fap_features, size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('../index.txt', 'r') as f:\n",
    "\tindex = f.read().split('\\n')\n",
    "\n",
    "from io import BytesIO\n",
    "import requests\n",
    "def load_image(url):\n",
    "\tresponse = requests.get(url)\n",
    "\tassert url[-4:] == '.jpg', url\n",
    "\timg = Image.open(BytesIO(response.content))\n",
    "\treturn img\n",
    "\n",
    "def load_index(idx):\n",
    "\turl = index[idx]\n",
    "\tprint('loading', url)\n",
    "\turl = 'https://my-project-420-353715.appspot.com.storage.googleapis.com/'+url\n",
    "\timg = load_image(url)\n",
    "\treturn img\n",
    "\n",
    "from IPython import display\n",
    "def display_index(idx):\n",
    "\tdisplay.display(load_index(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading database/fapello/models/abella-danger/abella-danger_0001.jpg\n",
      "0 0 0\n",
      "loading database/fapello/models/abigaiil-morris/abigaiil-morris_0011.jpg\n",
      "4 1024 1020\n",
      "loading database/fapello/models/adelalinka-twins/adelalinka-twins_0048.jpg\n",
      "0 2048 2048\n",
      "loading database/fapello/models/aery-tiefling/aery-tiefling_0100.jpg\n",
      "0 3072 3072\n",
      "loading database/fapello/models/agos-ashford/agos-ashford_0057.jpg\n",
      "0 4096 4096\n",
      "loading database/fapello/models/ai-generated-girls-1/ai-generated-girls-1_0146.jpg\n",
      "0 5120 5120\n",
      "loading database/fapello/models/aida-cortes/aida-cortes_0039.jpg\n",
      "0 6144 6144\n",
      "loading database/fapello/models/aisultana/aisultana_0375.jpg\n",
      "-822 7168 7990\n",
      "loading database/fapello/models/aisux/aisux_0770.jpg\n",
      "0 8192 8192\n",
      "loading database/fapello/models/alanah-pearce/alanah-pearce_0424.jpg\n",
      "0 9216 9216\n",
      "loading database/fapello/models/alcololi/alcololi_0677.jpg\n",
      "0 10240 10240\n",
      "loading database/fapello/models/alena-witch/alena-witch_0349.jpg\n",
      "0 11264 11264\n",
      "loading database/fapello/models/alexa-breit/alexa-breit_0270.jpg\n",
      "0 12288 12288\n",
      "loading database/fapello/models/alexa-pearl/alexa-pearl_0893.jpg\n",
      "0 13312 13312\n",
      "loading database/fapello/models/alexa-pearl/alexa-pearl_1917.jpg\n",
      "0 14336 14336\n",
      "loading database/fapello/models/alexa-pearl/alexa-pearl_2941.jpg\n",
      "0 15360 15360\n",
      "loading database/fapello/models/alexandra-bodler/alexandra-bodler_0774.jpg\n",
      "0 16384 16384\n",
      "loading database/fapello/models/alexandra-daddario/alexandra-daddario_0975.jpg\n",
      "0 17408 17408\n",
      "loading database/fapello/models/alice-delish/alice-delish_0068.jpg\n",
      "0 18432 18432\n",
      "loading database/fapello/models/alice-delish/alice-delish_1094.jpg\n",
      "0 19456 19456\n",
      "loading database/fapello/models/alice-delish/alice-delish_2119.jpg\n",
      "0 20480 20480\n",
      "loading database/fapello/models/alicebong/alicebong_0641.jpg\n",
      "0 21504 21504\n",
      "loading database/fapello/models/alina-becker/alina-becker_0886.jpg\n",
      "0 22528 22528\n",
      "loading database/fapello/models/alina-becker/alina-becker_1911.jpg\n",
      "0 23552 23552\n",
      "loading database/fapello/models/alina-becker/alina-becker_2935.jpg\n",
      "0 24576 24576\n",
      "loading database/fapello/models/alina-becker/alina-becker_3959.jpg\n",
      "0 25600 25600\n",
      "loading database/fapello/models/alina-becker/alina-becker_4989.jpg\n",
      "0 26624 26624\n",
      "loading database/fapello/models/alinity/alinity_0839.jpg\n",
      "0 27648 27648\n",
      "loading database/fapello/models/alissa-foxy/alissa-foxy_0161.jpg\n",
      "0 28672 28672\n",
      "loading database/fapello/models/alissa-foxy/alissa-foxy_1382.jpg\n",
      "0 29696 29696\n",
      "loading database/fapello/models/alissa-foxy/alissa-foxy_2407.jpg\n",
      "0 30720 30720\n",
      "loading database/fapello/models/alyri/alyri_0261.jpg\n",
      "0 31744 31744\n",
      "loading database/fapello/models/alyssa/alyssa_0345.jpg\n",
      "0 32768 32768\n",
      "loading database/fapello/models/alyssa9/alyssa9_0712.jpg\n",
      "0 33792 33792\n",
      "loading database/fapello/models/amanda-cerny/amanda-cerny_0604.jpg\n",
      "0 34816 34816\n",
      "loading database/fapello/models/amber-hahn/amber-hahn_0293.jpg\n",
      "0 35840 35840\n",
      "loading database/fapello/models/amber-hahn/amber-hahn_1317.jpg\n",
      "0 36864 36864\n",
      "loading database/fapello/models/ana-de-armas/ana-de-armas_0012.jpg\n",
      "0 37888 37888\n",
      "loading database/fapello/models/andrea-botez/andrea-botez_0243.jpg\n",
      "0 38912 38912\n",
      "loading database/fapello/models/anie-joy/anie-joy_0556.jpg\n",
      "0 39936 39936\n",
      "loading database/fapello/models/anna-tsaralunga/anna-tsaralunga_0074.jpg\n",
      "0 40960 40960\n",
      "loading database/fapello/models/anna-tsaralunga/anna-tsaralunga_1100.jpg\n",
      "0 41984 41984\n",
      "loading database/fapello/models/anna/anna_0095.jpg\n",
      "0 43008 43008\n",
      "loading database/fapello/models/annarita-esposito/annarita-esposito_0016.jpg\n",
      "0 44032 44032\n",
      "loading database/fapello/models/anya-taylor-joy/anya-taylor-joy_0217.jpg\n",
      "0 45056 45056\n",
      "loading database/fapello/models/ariana-grande-1/ariana-grande-1_0053.jpg\n",
      "0 46080 46080\n",
      "loading database/fapello/models/ariel-next-door/ariel-next-door_0231.jpg\n",
      "0 47104 47104\n",
      "loading database/fapello/models/ariel-winter/ariel-winter_0301.jpg\n",
      "0 48128 48128\n",
      "loading database/fapello/models/arty-huang/arty-huang_0463.jpg\n",
      "0 49152 49152\n",
      "loading database/fapello/models/asami-gate/asami-gate_0332.jpg\n",
      "0 50176 50176\n",
      "loading database/fapello/models/ashe-maree/ashe-maree_0327.jpg\n",
      "0 51200 51200\n",
      "loading database/fapello/models/ashley-marie-dickerson/ashley-marie-dickerson_0283.jpg\n",
      "0 52224 52224\n",
      "loading database/fapello/models/ashleytervort/ashleytervort_0114.jpg\n",
      "0 53248 53248\n",
      "loading database/fapello/models/asian-beauties/asian-beauties_0681.jpg\n",
      "0 54272 54272\n",
      "loading database/fapello/models/astasia-dream-2/astasia-dream-2_0031.jpg\n",
      "0 55296 55296\n",
      "loading database/fapello/models/astrid-wett/astrid-wett_0568.jpg\n",
      "0 56320 56320\n",
      "loading database/fapello/models/autumn-falls/autumn-falls_0350.jpg\n",
      "0 57344 57344\n",
      "loading database/fapello/models/azami/azami_0227.jpg\n",
      "0 58368 58368\n",
      "loading database/fapello/models/babyfooji/babyfooji_0572.jpg\n",
      "0 59392 59392\n",
      "loading database/fapello/models/babyjey/babyjey_0176.jpg\n",
      "0 60416 60416\n",
      "loading database/fapello/models/barbara-palvin/barbara-palvin_0259.jpg\n",
      "0 61440 61440\n",
      "loading database/fapello/models/bekejacoba/bekejacoba_0014.jpg\n",
      "0 62464 62464\n",
      "loading database/fapello/models/bella-poarch/bella-poarch_0047.jpg\n",
      "0 63488 63488\n",
      "loading database/fapello/models/berry/berry_0249.jpg\n",
      "0 64512 64512\n",
      "loading database/fapello/models/bethany-lily-april/bethany-lily-april_0335.jpg\n",
      "0 65536 65536\n",
      "loading database/fapello/models/bianca-karina/bianca-karina_0344.jpg\n",
      "0 66560 66560\n",
      "loading database/fapello/models/billie-eilish/billie-eilish_0630.jpg\n",
      "0 67584 67584\n",
      "loading database/fapello/models/bishoujomom/bishoujomom_0806.jpg\n",
      "0 68608 68608\n",
      "loading database/fapello/models/blinkksg/blinkksg_0131.jpg\n",
      "0 69632 69632\n",
      "loading database/fapello/models/bomi/bomi_0774.jpg\n",
      "0 70656 70656\n",
      "loading database/fapello/models/bonnie-stark/bonnie-stark_0787.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m idx \u001b[39m=\u001b[39m i\u001b[39m*\u001b[39m\u001b[39m1024\u001b[39m\n\u001b[0;32m      3\u001b[0m img \u001b[39m=\u001b[39m load_index(idx)\n\u001b[1;32m----> 4\u001b[0m b \u001b[39m=\u001b[39m sim_image(img, fap_features, \u001b[39m10\u001b[39;49m)[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m diff \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m b\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(diff, idx, b)\n",
      "Cell \u001b[1;32mIn[67], line 52\u001b[0m, in \u001b[0;36msim_image\u001b[1;34m(image, fap_features, size)\u001b[0m\n\u001b[0;32m     50\u001b[0m image \u001b[39m=\u001b[39m preprocess(image)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     51\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 52\u001b[0m \timage_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode_image(image)\n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m find_best_feature(image_features, fap_features, size)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\clip\\model.py:341\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_image\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[1;32m--> 341\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisual(image\u001b[39m.\u001b[39;49mtype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\clip\\model.py:232\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_pre(x)\n\u001b[0;32m    231\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# NLD -> LND\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(x)\n\u001b[0;32m    233\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# LND -> NLD\u001b[39;00m\n\u001b[0;32m    235\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_post(x[:, \u001b[39m0\u001b[39m, :])\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\clip\\model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblocks(x)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\container.py:117\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    116\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\clip\\model.py:191\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    190\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(x))\n\u001b[1;32m--> 191\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_2(x))\n\u001b[0;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\container.py:117\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    116\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\modules\\linear.py:93\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\onetaste108\\.conda\\envs\\fapp\\lib\\site-packages\\torch\\nn\\functional.py:1692\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39maddmm(bias, \u001b[39minput\u001b[39m, weight\u001b[39m.\u001b[39mt())\n\u001b[0;32m   1691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mmatmul(weight\u001b[39m.\u001b[39;49mt())\n\u001b[0;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1694\u001b[0m         output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bias\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, len(features_list), 1):\n",
    "\tidx = i*1024\n",
    "\timg = load_index(idx)\n",
    "\tb = sim_image(img, fap_features, 10)[1][0]\n",
    "\tdiff = idx - b\n",
    "\tprint(diff, idx, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading database/fapello/models/agos-ashford/agos-ashford_0561.jpg\n",
      "[4600 4608 4596 4458 4598 4601 4607 4886 4597 4595]\n"
     ]
    }
   ],
   "source": [
    "ref_id = 4600\n",
    "ref = load_index(ref_id)\n",
    "# ref = Image.open('../img/test1.jpg')\n",
    "# display.display(ref)\n",
    "\n",
    "# vb = sim_text('red dress', fap_features, 10)\n",
    "# vb = sim_image(ref, fap_features, 10)\n",
    "vb = sim_db(ref_id, fap_features, 10)\n",
    "print(vb[1])\n",
    "\n",
    "# for v, b in zip(*vb):\n",
    "# \tidx = b if b < 1024 else b+1024\n",
    "# \tprint(idx)\n",
    "# \tdisplay_index(idx)\n",
    "# \tprint('Value:', v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "features_dir = '../weights'\n",
    "fps = os.listdir(features_dir)\n",
    "\n",
    "indices = [int(f.split('.')[0]) for f in fps]\n",
    "indices.sort()\n",
    "\n",
    "all_size = 0\n",
    "features = []\n",
    "for idx in indices:\n",
    "\tarr = np.load(features_dir+'/'+f'{idx}.npy')[0]\n",
    "\tarr = np.float32(arr)\n",
    "\t# print(f'{idx+512}.npy', arr[0][:5])\n",
    "\t# print([arr[i][0] for i in range(8)])\n",
    "\tall_size += arr.shape[0]\n",
    "\tfeatures.append(arr)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(features)-1):\n",
    "\tif np.mean(np.abs(features[i] - features[i+1])) < 0.2:\n",
    "\t\tcount += 1\n",
    "\t\t\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m n \u001b[39m=\u001b[39m image_features\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      2\u001b[0m n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([n,n,n])\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(n\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_features' is not defined"
     ]
    }
   ],
   "source": [
    "n = image_features.cpu().numpy()\n",
    "n = np.array([n,n,n])\n",
    "print(n.dtype)\n",
    "np.save('test', n)\n",
    "n2 = np.load('../weights/clip512.npy')\n",
    "print(n2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.1383 , -0.746  ,  0.296  , ...,  0.128  ,  0.05353,\n",
       "         -0.4373 ]],\n",
       "\n",
       "       [[-0.1383 , -0.746  ,  0.296  , ...,  0.128  ,  0.05353,\n",
       "         -0.4373 ]]], dtype=float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [f,f]\n",
    "np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m obj \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m \tpickle\u001b[39m.\u001b[39;49mdump(obj, f)\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "obj = [1,2]\n",
    "with open(\"test.pkl\", \"w\") as f:\n",
    "\tpickle.dump(obj, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5007d5fb941a5d0afa29e01279b274eb1b997d54b24126c98117c79df6439ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
